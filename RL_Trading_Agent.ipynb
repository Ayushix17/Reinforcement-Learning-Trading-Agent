{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a51e69da-6ce4-425f-9e50-23a77e308507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: yfinance in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (0.2.65)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from yfinance) (2.1.4)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from yfinance) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\programdata\\anaconda3\\lib\\site-packages (from yfinance) (2.31.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from yfinance) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from yfinance) (2023.3.post1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from yfinance) (2.4.2)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from yfinance) (3.18.2)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from yfinance) (4.12.2)\n",
      "Requirement already satisfied: curl_cffi>=0.7 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from yfinance) (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from yfinance) (3.20.3)\n",
      "Requirement already satisfied: websockets>=13.0 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from yfinance) (15.0.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: cffi>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from curl_cffi>=0.7->yfinance) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from curl_cffi>=0.7->yfinance) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (2.0.7)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67e24b32-41e3-4b14-8048-008ddeff6e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb7d9d7d-b11f-4a97-bf7d-943c5b926c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AI Trading Agent with Reinforcement Learning ===\n",
      "\n",
      "Checking dependencies...\n",
      "NumPy/Pandas: Available\n",
      "yfinance: Available\n",
      "TensorFlow: Available\n",
      "Matplotlib: Available\n",
      "\n",
      "Training AI Trading Agent for AAPL...\n",
      "Episode 0/50, Score: -0.64, Portfolio Value: 9983.71, Epsilon: 0.99\n",
      "Episode 20/50, Score: -0.60, Portfolio Value: 9984.81, Epsilon: 0.90\n",
      "Episode 40/50, Score: -0.66, Portfolio Value: 9949.01, Epsilon: 0.81\n",
      "\n",
      "Evaluating trained agent...\n",
      "\n",
      "=== Evaluation Results ===\n",
      "Initial Balance: $10,000.00\n",
      "Final Portfolio Value: $9,985.25\n",
      "Total Return: -0.15%\n",
      "Market Return: -14.42%\n",
      "Alpha (Excess Return): 14.28%\n",
      "Number of Trades: 38\n",
      "\n",
      "Training completed successfully!\n",
      "\n",
      "To install optional dependencies:\n",
      "pip install yfinance tensorflow matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from collections import deque\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "# Try to import optional dependencies\n",
    "try:\n",
    "    import yfinance as yf\n",
    "    HAS_YFINANCE = True\n",
    "except ImportError:\n",
    "    HAS_YFINANCE = False\n",
    "    print(\"yfinance not available. Install with: pip install yfinance\")\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    HAS_TENSORFLOW = True\n",
    "except ImportError:\n",
    "    HAS_TENSORFLOW = False\n",
    "    print(\"tensorflow not available. Install with: pip install tensorflow\")\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    HAS_MATPLOTLIB = True\n",
    "except ImportError:\n",
    "    HAS_MATPLOTLIB = False\n",
    "    print(\"matplotlib not available. Install with: pip install matplotlib\")\n",
    "\n",
    "# Simple gym-like environment base classes (no external dependency)\n",
    "class Space:\n",
    "    \"\"\"Base class for observation and action spaces\"\"\"\n",
    "    pass\n",
    "\n",
    "class Discrete(Space):\n",
    "    \"\"\"Discrete action space\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "    \n",
    "    def sample(self):\n",
    "        return np.random.randint(0, self.n)\n",
    "\n",
    "class Box(Space):\n",
    "    \"\"\"Continuous space with bounds\"\"\"\n",
    "    def __init__(self, low, high, shape, dtype=np.float32):\n",
    "        self.low = low\n",
    "        self.high = high\n",
    "        self.shape = shape\n",
    "        self.dtype = dtype\n",
    "    \n",
    "    def sample(self):\n",
    "        return np.random.uniform(self.low, self.high, self.shape).astype(self.dtype)\n",
    "\n",
    "# ===============================\n",
    "# Financial Data API Integration\n",
    "# ===============================\n",
    "\n",
    "class FinancialDataProvider:\n",
    "    \"\"\"Unified interface for financial data from multiple sources\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha_vantage_key=None):\n",
    "        self.alpha_vantage_key = alpha_vantage_key\n",
    "    \n",
    "    def get_yahoo_data(self, symbol, period=\"1y\", interval=\"1d\"):\n",
    "        \"\"\"Get data from Yahoo Finance\"\"\"\n",
    "        if not HAS_YFINANCE:\n",
    "            print(\"yfinance not installed. Using sample data.\")\n",
    "            return self._generate_sample_data()\n",
    "        \n",
    "        try:\n",
    "            ticker = yf.Ticker(symbol)\n",
    "            data = ticker.history(period=period, interval=interval)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching Yahoo data: {e}\")\n",
    "            print(\"Using sample data instead.\")\n",
    "            return self._generate_sample_data()\n",
    "    \n",
    "    def _generate_sample_data(self):\n",
    "        \"\"\"Generate sample stock data for testing\"\"\"\n",
    "        np.random.seed(42)\n",
    "        dates = pd.date_range(start='2022-01-01', end='2024-01-01', freq='D')\n",
    "        n_days = len(dates)\n",
    "        \n",
    "        # Generate realistic stock price data using geometric Brownian motion\n",
    "        initial_price = 100\n",
    "        drift = 0.0005  # Daily drift\n",
    "        volatility = 0.02  # Daily volatility\n",
    "        \n",
    "        returns = np.random.normal(drift, volatility, n_days)\n",
    "        prices = [initial_price]\n",
    "        \n",
    "        for i in range(1, n_days):\n",
    "            price = prices[-1] * (1 + returns[i])\n",
    "            prices.append(price)\n",
    "        \n",
    "        # Create OHLCV data\n",
    "        data = pd.DataFrame(index=dates)\n",
    "        data['Close'] = prices\n",
    "        data['Open'] = data['Close'].shift(1) * (1 + np.random.normal(0, 0.005, n_days))\n",
    "        data['High'] = data[['Open', 'Close']].max(axis=1) * (1 + np.abs(np.random.normal(0, 0.01, n_days)))\n",
    "        data['Low'] = data[['Open', 'Close']].min(axis=1) * (1 - np.abs(np.random.normal(0, 0.01, n_days)))\n",
    "        data['Volume'] = np.random.lognormal(10, 1, n_days)\n",
    "        \n",
    "        data = data.dropna()\n",
    "        return data\n",
    "    \n",
    "    def get_alpha_vantage_data(self, symbol, function=\"TIME_SERIES_DAILY\"):\n",
    "        \"\"\"Get data from Alpha Vantage API\"\"\"\n",
    "        if not self.alpha_vantage_key:\n",
    "            print(\"Alpha Vantage API key not provided\")\n",
    "            return None\n",
    "        \n",
    "        url = f'https://www.alphavantage.co/query'\n",
    "        params = {\n",
    "            'function': function,\n",
    "            'symbol': symbol,\n",
    "            'apikey': self.alpha_vantage_key,\n",
    "            'outputsize': 'full'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, params=params)\n",
    "            data = response.json()\n",
    "            \n",
    "            if \"Time Series (Daily)\" in data:\n",
    "                df = pd.DataFrame(data[\"Time Series (Daily)\"]).T\n",
    "                df.index = pd.to_datetime(df.index)\n",
    "                df = df.astype(float)\n",
    "                df.columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "                return df\n",
    "            else:\n",
    "                print(\"Error in API response:\", data.get('Error Message', 'Unknown error'))\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching Alpha Vantage data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_crypto_data(self, symbol, vs_currency=\"usd\", days=365):\n",
    "        \"\"\"Get cryptocurrency data from CoinGecko API\"\"\"\n",
    "        url = f\"https://api.coingecko.com/api/v3/coins/{symbol}/market_chart\"\n",
    "        params = {\n",
    "            'vs_currency': vs_currency,\n",
    "            'days': days,\n",
    "            'interval': 'daily'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, params=params)\n",
    "            data = response.json()\n",
    "            \n",
    "            prices = data['prices']\n",
    "            volumes = data['total_volumes']\n",
    "            \n",
    "            df = pd.DataFrame(prices, columns=['timestamp', 'price'])\n",
    "            df['volume'] = [vol[1] for vol in volumes]\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "            df.set_index('timestamp', inplace=True)\n",
    "            \n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching crypto data: {e}\")\n",
    "            return None\n",
    "\n",
    "# ===============================\n",
    "# Technical Indicators\n",
    "# ===============================\n",
    "\n",
    "class TechnicalIndicators:\n",
    "    \"\"\"Calculate various technical indicators\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def sma(data, window):\n",
    "        \"\"\"Simple Moving Average\"\"\"\n",
    "        return data.rolling(window=window).mean()\n",
    "    \n",
    "    @staticmethod\n",
    "    def ema(data, window):\n",
    "        \"\"\"Exponential Moving Average\"\"\"\n",
    "        return data.ewm(span=window).mean()\n",
    "    \n",
    "    @staticmethod\n",
    "    def rsi(data, window=14):\n",
    "        \"\"\"Relative Strength Index\"\"\"\n",
    "        delta = data.diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "        rs = gain / loss\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        return rsi\n",
    "    \n",
    "    @staticmethod\n",
    "    def bollinger_bands(data, window=20, num_std=2):\n",
    "        \"\"\"Bollinger Bands\"\"\"\n",
    "        sma = data.rolling(window=window).mean()\n",
    "        std = data.rolling(window=window).std()\n",
    "        upper_band = sma + (std * num_std)\n",
    "        lower_band = sma - (std * num_std)\n",
    "        return upper_band, sma, lower_band\n",
    "    \n",
    "    @staticmethod\n",
    "    def macd(data, fast=12, slow=26, signal=9):\n",
    "        \"\"\"MACD Indicator\"\"\"\n",
    "        exp1 = data.ewm(span=fast).mean()\n",
    "        exp2 = data.ewm(span=slow).mean()\n",
    "        macd_line = exp1 - exp2\n",
    "        signal_line = macd_line.ewm(span=signal).mean()\n",
    "        histogram = macd_line - signal_line\n",
    "        return macd_line, signal_line, histogram\n",
    "\n",
    "# ===============================\n",
    "# Custom Trading Environment\n",
    "# ===============================\n",
    "\n",
    "class TradingEnvironment:\n",
    "    \"\"\"Custom trading environment for RL agents (no external gym dependency)\"\"\"\n",
    "    \n",
    "    def __init__(self, data, initial_balance=10000, transaction_cost=0.001, \n",
    "                 max_position=1.0, lookback_window=20):\n",
    "        \n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.initial_balance = initial_balance\n",
    "        self.transaction_cost = transaction_cost\n",
    "        self.max_position = max_position\n",
    "        self.lookback_window = lookback_window\n",
    "        \n",
    "        # Action space: 0=Hold, 1=Buy, 2=Sell\n",
    "        self.action_space = Discrete(3)\n",
    "        \n",
    "        # Observation space: price data + technical indicators + portfolio state\n",
    "        self.observation_space = Box(\n",
    "            low=-np.inf, high=np.inf, \n",
    "            shape=(self.lookback_window * 8 + 3,), \n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self, seed=None):\n",
    "        \"\"\"Reset the environment\"\"\"\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "            random.seed(seed)\n",
    "        \n",
    "        self.current_step = self.lookback_window\n",
    "        self.balance = self.initial_balance\n",
    "        self.position = 0.0  # -1 to 1 (short to long)\n",
    "        self.total_profit = 0.0\n",
    "        self.trades = []\n",
    "        self.portfolio_values = []\n",
    "        \n",
    "        return self._get_observation(), {}\n",
    "    \n",
    "    def _get_observation(self):\n",
    "        \"\"\"Get current observation state\"\"\"\n",
    "        # Get lookback window of data\n",
    "        start_idx = max(0, self.current_step - self.lookback_window)\n",
    "        end_idx = self.current_step\n",
    "        \n",
    "        window_data = self.data.iloc[start_idx:end_idx]\n",
    "        \n",
    "        # Price features (normalized)\n",
    "        prices = window_data['Close'].values\n",
    "        price_returns = np.diff(np.log(prices + 1e-8))\n",
    "        price_returns = np.pad(price_returns, (1, 0), 'constant', constant_values=0)\n",
    "        \n",
    "        volumes = window_data['Volume'].values\n",
    "        volume_ma = np.mean(volumes)\n",
    "        volume_norm = volumes / (volume_ma + 1e-8)\n",
    "        \n",
    "        # Technical indicators\n",
    "        ti = TechnicalIndicators()\n",
    "        \n",
    "        # Ensure we have enough data for indicators\n",
    "        if len(window_data) >= 20:\n",
    "            rsi = ti.rsi(window_data['Close'], 14).fillna(50).values\n",
    "            macd, signal, _ = ti.macd(window_data['Close'])\n",
    "            macd = macd.fillna(0).values\n",
    "            signal = signal.fillna(0).values\n",
    "            \n",
    "            sma_20 = ti.sma(window_data['Close'], 20).fillna(method='ffill').fillna(window_data['Close'].iloc[0]).values\n",
    "            price_to_sma = prices / (sma_20 + 1e-8)\n",
    "            \n",
    "            upper_bb, middle_bb, lower_bb = ti.bollinger_bands(window_data['Close'], 20)\n",
    "            # Fix the fillna issue by using scalar values\n",
    "            upper_bb_filled = upper_bb.fillna(method='ffill').fillna(window_data['Close'].iloc[-1])\n",
    "            lower_bb_filled = lower_bb.fillna(method='ffill').fillna(window_data['Close'].iloc[-1])\n",
    "            \n",
    "            # Convert to numpy arrays for calculation\n",
    "            upper_bb_vals = upper_bb_filled.values\n",
    "            lower_bb_vals = lower_bb_filled.values\n",
    "            \n",
    "            bb_position = (prices - lower_bb_vals) / (upper_bb_vals - lower_bb_vals + 1e-8)\n",
    "            # Handle any remaining NaN values\n",
    "            bb_position = np.nan_to_num(bb_position, nan=0.5)\n",
    "        else:\n",
    "            # Fill with neutral values if not enough data\n",
    "            rsi = np.full(len(window_data), 50)\n",
    "            macd = np.zeros(len(window_data))\n",
    "            signal = np.zeros(len(window_data))\n",
    "            price_to_sma = np.ones(len(window_data))\n",
    "            bb_position = np.full(len(window_data), 0.5)\n",
    "        \n",
    "        # Pad arrays to consistent length\n",
    "        target_length = self.lookback_window\n",
    "        arrays_to_pad = [price_returns, volume_norm, rsi/100, macd, signal, \n",
    "                        price_to_sma, bb_position, prices/np.mean(prices)]\n",
    "        \n",
    "        padded_arrays = []\n",
    "        for arr in arrays_to_pad:\n",
    "            if len(arr) < target_length:\n",
    "                padded = np.pad(arr, (target_length - len(arr), 0), 'constant', \n",
    "                               constant_values=arr[0] if len(arr) > 0 else 0)\n",
    "            else:\n",
    "                padded = arr[-target_length:]\n",
    "            padded_arrays.append(padded)\n",
    "        \n",
    "        # Flatten all features\n",
    "        features = np.concatenate(padded_arrays)\n",
    "        \n",
    "        # Portfolio state\n",
    "        portfolio_state = np.array([\n",
    "            self.position,\n",
    "            self.balance / self.initial_balance,\n",
    "            self.total_profit / self.initial_balance\n",
    "        ])\n",
    "        \n",
    "        observation = np.concatenate([features, portfolio_state]).astype(np.float32)\n",
    "        return observation\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"Execute one step in the environment\"\"\"\n",
    "        current_price = self.data.iloc[self.current_step]['Close']\n",
    "        \n",
    "        # Execute action\n",
    "        reward = 0\n",
    "        old_position = self.position\n",
    "        \n",
    "        if action == 1:  # Buy\n",
    "            if self.position < self.max_position:\n",
    "                trade_amount = min(0.1, self.max_position - self.position)\n",
    "                cost = trade_amount * current_price * (1 + self.transaction_cost)\n",
    "                if cost <= self.balance:\n",
    "                    self.position += trade_amount\n",
    "                    self.balance -= cost\n",
    "                    self.trades.append(('BUY', self.current_step, current_price, trade_amount))\n",
    "        \n",
    "        elif action == 2:  # Sell\n",
    "            if self.position > -self.max_position:\n",
    "                trade_amount = min(0.1, self.position + self.max_position)\n",
    "                if trade_amount > 0:\n",
    "                    proceeds = trade_amount * current_price * (1 - self.transaction_cost)\n",
    "                    self.position -= trade_amount\n",
    "                    self.balance += proceeds\n",
    "                    self.trades.append(('SELL', self.current_step, current_price, trade_amount))\n",
    "        \n",
    "        # Calculate portfolio value and reward\n",
    "        portfolio_value = self.balance + self.position * current_price\n",
    "        self.portfolio_values.append(portfolio_value)\n",
    "        \n",
    "        # Reward calculation\n",
    "        if len(self.portfolio_values) > 1:\n",
    "            portfolio_return = (portfolio_value - self.portfolio_values[-2]) / self.portfolio_values[-2]\n",
    "            market_return = 0\n",
    "            if self.current_step > 0:\n",
    "                prev_price = self.data.iloc[self.current_step - 1]['Close']\n",
    "                market_return = (current_price - prev_price) / prev_price\n",
    "            \n",
    "            # Reward based on portfolio performance vs market\n",
    "            reward = portfolio_return - market_return\n",
    "            \n",
    "            # Penalty for excessive trading\n",
    "            if action != 0:  # If not holding\n",
    "                reward -= 0.001\n",
    "        \n",
    "        self.current_step += 1\n",
    "        self.total_profit = portfolio_value - self.initial_balance\n",
    "        \n",
    "        # Check if episode is done\n",
    "        done = self.current_step >= len(self.data) - 1\n",
    "        \n",
    "        info = {\n",
    "            'portfolio_value': portfolio_value,\n",
    "            'position': self.position,\n",
    "            'balance': self.balance,\n",
    "            'total_return': (portfolio_value - self.initial_balance) / self.initial_balance\n",
    "        }\n",
    "        \n",
    "        return self._get_observation(), reward, done, False, info\n",
    "    \n",
    "    def render(self):\n",
    "        \"\"\"Render the environment (optional)\"\"\"\n",
    "        if len(self.portfolio_values) > 0:\n",
    "            print(f\"Step: {self.current_step}, Portfolio Value: {self.portfolio_values[-1]:.2f}, \"\n",
    "                  f\"Position: {self.position:.2f}, Balance: {self.balance:.2f}\")\n",
    "\n",
    "# ===============================\n",
    "# Deep Q-Network Agent\n",
    "# ===============================\n",
    "\n",
    "class DQNAgent:\n",
    "    \"\"\"Deep Q-Network agent for trading (with fallback to simple Q-learning)\"\"\"\n",
    "    \n",
    "    def __init__(self, state_size, action_size, learning_rate=0.001):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.batch_size = 32\n",
    "        \n",
    "        # Initialize use_neural_network first\n",
    "        self.use_neural_network = HAS_TENSORFLOW\n",
    "        \n",
    "        if HAS_TENSORFLOW:\n",
    "            self.q_network = self._build_model()\n",
    "            self.target_network = self._build_model()\n",
    "            self.update_target_network()\n",
    "        else:\n",
    "            # Fallback to simple Q-table with state discretization\n",
    "            print(\"TensorFlow not available. Using simplified Q-learning with state discretization.\")\n",
    "            self.q_table = {}\n",
    "            self.q_network = None\n",
    "            self.target_network = None\n",
    "    \n",
    "    def _build_model(self):\n",
    "        \"\"\"Build the neural network model\"\"\"\n",
    "        if not HAS_TENSORFLOW:\n",
    "            return None\n",
    "            \n",
    "        model = keras.Sequential([\n",
    "            layers.Dense(128, input_shape=(self.state_size,), activation='relu'),\n",
    "            layers.Dropout(0.2),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dropout(0.2),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(self.action_size, activation='linear')\n",
    "        ])\n",
    "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=self.learning_rate),\n",
    "                     loss='mse')\n",
    "        return model\n",
    "    \n",
    "    def _discretize_state(self, state):\n",
    "        \"\"\"Discretize continuous state for Q-table\"\"\"\n",
    "        # Simple discretization - bin key features\n",
    "        price_change = int(state[0] * 100) // 5  # Group price changes into bins\n",
    "        rsi = int(state[self.state_size//4] * 20)  # RSI discretized\n",
    "        position = int(state[-3] * 10)  # Position discretized\n",
    "        \n",
    "        return (price_change, rsi, position)\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Store experience in replay buffer\"\"\"\n",
    "        if self.use_neural_network:\n",
    "            self.memory.append((state, action, reward, next_state, done))\n",
    "        else:\n",
    "            # For Q-table, update immediately\n",
    "            self._update_q_table(state, action, reward, next_state, done)\n",
    "    \n",
    "    def _update_q_table(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Update Q-table (fallback method)\"\"\"\n",
    "        state_key = self._discretize_state(state)\n",
    "        next_state_key = self._discretize_state(next_state)\n",
    "        \n",
    "        if state_key not in self.q_table:\n",
    "            self.q_table[state_key] = np.zeros(self.action_size)\n",
    "        \n",
    "        if next_state_key not in self.q_table:\n",
    "            self.q_table[next_state_key] = np.zeros(self.action_size)\n",
    "        \n",
    "        # Q-learning update\n",
    "        if done:\n",
    "            target = reward\n",
    "        else:\n",
    "            target = reward + 0.95 * np.max(self.q_table[next_state_key])\n",
    "        \n",
    "        self.q_table[state_key][action] += self.learning_rate * (target - self.q_table[state_key][action])\n",
    "    \n",
    "    def act(self, state):\n",
    "        \"\"\"Choose action using epsilon-greedy policy\"\"\"\n",
    "        if np.random.random() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        \n",
    "        if self.use_neural_network:\n",
    "            q_values = self.q_network.predict(state.reshape(1, -1), verbose=0)\n",
    "            return np.argmax(q_values[0])\n",
    "        else:\n",
    "            # Use Q-table\n",
    "            state_key = self._discretize_state(state)\n",
    "            if state_key in self.q_table:\n",
    "                return np.argmax(self.q_table[state_key])\n",
    "            else:\n",
    "                return random.randrange(self.action_size)\n",
    "    \n",
    "    def replay(self):\n",
    "        \"\"\"Train the model on a batch of experiences\"\"\"\n",
    "        if not self.use_neural_network:\n",
    "            # Q-table updates happen immediately in remember()\n",
    "            if self.epsilon > self.epsilon_min:\n",
    "                self.epsilon *= self.epsilon_decay\n",
    "            return\n",
    "            \n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "        \n",
    "        batch = random.sample(self.memory, self.batch_size)\n",
    "        states = np.array([e[0] for e in batch])\n",
    "        actions = np.array([e[1] for e in batch])\n",
    "        rewards = np.array([e[2] for e in batch])\n",
    "        next_states = np.array([e[3] for e in batch])\n",
    "        dones = np.array([e[4] for e in batch])\n",
    "        \n",
    "        current_q_values = self.q_network.predict(states, verbose=0)\n",
    "        next_q_values = self.target_network.predict(next_states, verbose=0)\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            if dones[i]:\n",
    "                current_q_values[i][actions[i]] = rewards[i]\n",
    "            else:\n",
    "                current_q_values[i][actions[i]] = rewards[i] + 0.95 * np.max(next_q_values[i])\n",
    "        \n",
    "        self.q_network.fit(states, current_q_values, epochs=1, verbose=0)\n",
    "        \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "    \n",
    "    def update_target_network(self):\n",
    "        \"\"\"Update target network weights\"\"\"\n",
    "        if self.use_neural_network and self.target_network is not None:\n",
    "            self.target_network.set_weights(self.q_network.get_weights())\n",
    "\n",
    "# ===============================\n",
    "# Training and Evaluation\n",
    "# ===============================\n",
    "\n",
    "class TradingAgentTrainer:\n",
    "    \"\"\"Trainer for the trading agent\"\"\"\n",
    "    \n",
    "    def __init__(self, symbol=\"AAPL\", data_provider=None):\n",
    "        self.symbol = symbol\n",
    "        self.data_provider = data_provider or FinancialDataProvider()\n",
    "        \n",
    "    def prepare_data(self, train_split=0.8):\n",
    "        \"\"\"Prepare training and testing data\"\"\"\n",
    "        # Try Yahoo Finance first\n",
    "        data = self.data_provider.get_yahoo_data(self.symbol, period=\"2y\", interval=\"1d\")\n",
    "        \n",
    "        if data is None or data.empty:\n",
    "            print(f\"Could not fetch data for {self.symbol}\")\n",
    "            return None, None\n",
    "        \n",
    "        # Clean data\n",
    "        data = data.dropna()\n",
    "        data.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Split data\n",
    "        split_index = int(len(data) * train_split)\n",
    "        train_data = data.iloc[:split_index].copy()\n",
    "        test_data = data.iloc[split_index:].copy()\n",
    "        \n",
    "        return train_data, test_data\n",
    "    \n",
    "    def train_agent(self, episodes=100):\n",
    "        \"\"\"Train the DQN agent\"\"\"\n",
    "        train_data, test_data = self.prepare_data()\n",
    "        \n",
    "        if train_data is None:\n",
    "            return None, None\n",
    "        \n",
    "        # Create environment\n",
    "        env = TradingEnvironment(train_data)\n",
    "        state_size = env.observation_space.shape[0]\n",
    "        action_size = env.action_space.n\n",
    "        \n",
    "        # Create agent\n",
    "        agent = DQNAgent(state_size, action_size)\n",
    "        \n",
    "        # Training loop\n",
    "        scores = []\n",
    "        portfolio_values = []\n",
    "        \n",
    "        for episode in range(episodes):\n",
    "            state, _ = env.reset()\n",
    "            total_reward = 0\n",
    "            \n",
    "            while True:\n",
    "                action = agent.act(state)\n",
    "                next_state, reward, done, truncated, info = env.step(action)\n",
    "                agent.remember(state, action, reward, next_state, done)\n",
    "                \n",
    "                state = next_state\n",
    "                total_reward += reward\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "            \n",
    "            agent.replay()\n",
    "            if episode % 10 == 0:\n",
    "                agent.update_target_network()\n",
    "            \n",
    "            scores.append(total_reward)\n",
    "            portfolio_values.append(info['portfolio_value'])\n",
    "            \n",
    "            if episode % 20 == 0:\n",
    "                print(f\"Episode {episode}/{episodes}, Score: {total_reward:.2f}, \"\n",
    "                      f\"Portfolio Value: {info['portfolio_value']:.2f}, \"\n",
    "                      f\"Epsilon: {agent.epsilon:.2f}\")\n",
    "        \n",
    "        return agent, env\n",
    "    \n",
    "    def evaluate_agent(self, agent, test_data):\n",
    "        \"\"\"Evaluate the trained agent\"\"\"\n",
    "        test_env = TradingEnvironment(test_data)\n",
    "        state, _ = test_env.reset()\n",
    "        \n",
    "        total_reward = 0\n",
    "        portfolio_values = []\n",
    "        actions_taken = []\n",
    "        \n",
    "        while True:\n",
    "            action = agent.act(state)\n",
    "            state, reward, done, truncated, info = test_env.step(action)\n",
    "            \n",
    "            total_reward += reward\n",
    "            portfolio_values.append(info['portfolio_value'])\n",
    "            actions_taken.append(action)\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        # Calculate metrics\n",
    "        final_value = portfolio_values[-1]\n",
    "        total_return = (final_value - test_env.initial_balance) / test_env.initial_balance\n",
    "        \n",
    "        # Calculate market return for comparison\n",
    "        start_price = test_data.iloc[0]['Close']\n",
    "        end_price = test_data.iloc[-1]['Close']\n",
    "        market_return = (end_price - start_price) / start_price\n",
    "        \n",
    "        print(\"\\n=== Evaluation Results ===\")\n",
    "        print(f\"Initial Balance: ${test_env.initial_balance:,.2f}\")\n",
    "        print(f\"Final Portfolio Value: ${final_value:,.2f}\")\n",
    "        print(f\"Total Return: {total_return:.2%}\")\n",
    "        print(f\"Market Return: {market_return:.2%}\")\n",
    "        print(f\"Alpha (Excess Return): {(total_return - market_return):.2%}\")\n",
    "        print(f\"Number of Trades: {len(test_env.trades)}\")\n",
    "        \n",
    "        return {\n",
    "            'portfolio_values': portfolio_values,\n",
    "            'actions': actions_taken,\n",
    "            'total_return': total_return,\n",
    "            'market_return': market_return,\n",
    "            'final_value': final_value,\n",
    "            'trades': test_env.trades\n",
    "        }\n",
    "\n",
    "# ===============================\n",
    "# Example Usage\n",
    "# ===============================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to demonstrate the trading agent\"\"\"\n",
    "    \n",
    "    print(\"=== AI Trading Agent with Reinforcement Learning ===\")\n",
    "    print(\"\\nChecking dependencies...\")\n",
    "    print(f\"NumPy/Pandas: Available\")\n",
    "    print(f\"yfinance: {'Available' if HAS_YFINANCE else 'Not Available (will use sample data)'}\")\n",
    "    print(f\"TensorFlow: {'Available' if HAS_TENSORFLOW else 'Not Available (will use Q-table)'}\")\n",
    "    print(f\"Matplotlib: {'Available' if HAS_MATPLOTLIB else 'Not Available (no plots)'}\")\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = TradingAgentTrainer(symbol=\"AAPL\")\n",
    "    \n",
    "    print(f\"\\nTraining AI Trading Agent for {trainer.symbol}...\")\n",
    "    agent, train_env = trainer.train_agent(episodes=50 if HAS_TENSORFLOW else 100)\n",
    "    \n",
    "    if agent is None:\n",
    "        print(\"Training failed - could not fetch or generate data\")\n",
    "        return\n",
    "    \n",
    "    # Get test data for evaluation\n",
    "    _, test_data = trainer.prepare_data()\n",
    "    \n",
    "    print(\"\\nEvaluating trained agent...\")\n",
    "    results = trainer.evaluate_agent(agent, test_data)\n",
    "    \n",
    "    # Simple text-based visualization if no matplotlib\n",
    "    if not HAS_MATPLOTLIB:\n",
    "        print(\"\\n=== Portfolio Performance ===\")\n",
    "        portfolio_values = results['portfolio_values']\n",
    "        print(f\"Starting Value: ${portfolio_values[0]:,.2f}\")\n",
    "        print(f\"Ending Value: ${portfolio_values[-1]:,.2f}\")\n",
    "        print(f\"Peak Value: ${max(portfolio_values):,.2f}\")\n",
    "        print(f\"Lowest Value: ${min(portfolio_values):,.2f}\")\n",
    "        \n",
    "        # Show some key trading points\n",
    "        actions = results['actions']\n",
    "        buy_count = sum(1 for a in actions if a == 1)\n",
    "        sell_count = sum(1 for a in actions if a == 2)\n",
    "        hold_count = sum(1 for a in actions if a == 0)\n",
    "        \n",
    "        print(f\"\\n=== Trading Activity ===\")\n",
    "        print(f\"Buy signals: {buy_count}\")\n",
    "        print(f\"Sell signals: {sell_count}\")\n",
    "        print(f\"Hold periods: {hold_count}\")\n",
    "    \n",
    "    print(\"\\nTraining completed successfully!\")\n",
    "    print(\"\\nTo install optional dependencies:\")\n",
    "    print(\"pip install yfinance tensorflow matplotlib\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
